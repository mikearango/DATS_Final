---
title: "Using Neighborhood Level Data to Predict the Residential Sale Price of Properties in Ames, Iowa"
author: "Yeshwant Chillakuru, Michael Arango, Jack Crum, Paul Brewster"
date: "4/28/2017"
output:
  html_document:
    highlight: textmate
    theme: yeti
    toc: yes
    fontsize: 11
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Intro

The 2008 financial crisis affected the lives of everyone in the United States---some more than others---and there is an abundance of retrospective research that seeks to identify which sectors of the economy were hit hardest during this time and why. The first sector that comes to mind is housing as the financial crisis was "characterized by a rise in subprime mortgage delinquencies and foreclosures, and the resulting decline of securities" backed by these subprime mortgages.[1] For this reason, we decided to use our multifaceted data science toolbox to answer meaningful questions about the housing market. The goal of this project is ultimately to build a regression model to predict defined outcomes. So, while we will not be analyzing the housing market from an economic perspective like the majority of the literature, we can offer up a predictive model for academic purposes. 

As a conceptual framework for our research, we adopted Peng and Matsui's epicycles of analysis to iteratively manage the steps of our data analysis.[2] After choosing the broad topic of the housing market, we narrowed the scope of our research. This included brainstorming as a team to figure out what specific question we wanted to answer about the housing market. We unanimously decided to predict the sale price of a residential house sale based on common characteristics that a property appraiser or assessor's office would use to assess property value. 

**Maybe add small lit review section here**

## The Dataset

The dataset we chose for our project contains information from the Ames Assessorâ€™s Office on residential property sales that occurred in Ames, Iowa from 2006 to 2010.[3] The dataset was published in the *Journal of Statistics Education* for students and researchers alike to have an opportunity to practice predictive modeling on messy, real world data. The dataset contains 2930 observations of 80 variables and the unit of observation is a single property sale in Ames, Iowa in a given year.

Of the 80 variables, 23 are nominal, 23 are ordinal, 14 are discrete, and 20 are continuous. The variables included are basic characteristics that anyone wanting to buy a house would be interested in. For the most part, the different variables may be split up into specific groups. In general, the 20 continuous variables relate to  measurements of area dimensions for each observation. These include, among others, the sizes of lots, rooms, porches, and garages. The 14 discrete variables mostly have to do with the number of bedrooms, bathrooms, kitchens, etc. that a given property has. There are several geographic categorical variables that start profiling properties at the individual Parcel ID level and end at the neighborhood level. The rest of the nominal variables identify characteristics of the property and dwelling type/structure. Most of the ordinal variables are rankings of the quality/condition of rooms and lot characteristics. For more information on the variables in the dataset, consult the included `DataDescription.txt` file.

The dataset was fairly messy with regard to the number of missing values and the way levels of categorical variables were organized and coded. In order to tackle the large amount of cleaning required, we thought it was best to split the data into four equal parts---leaving about 20 variables for each team member to clean. So, we changed all variable names to lowercase as some were upper case to standardize them and divided the variables up accordingly. 

There were 13960 missing values in the dataset when we started to clean and analyze it. *Table 1* breaks down the number of missing values by variable. After analyzing the variables with missing data and consulting the aforementioned `DataDescription.txt` file, we noticed that most of the missing values were actually not missing. The documentation states the data curator coded certain variables as `NA` to specify that a house did not have that feature. For example, in the case of the `alley` variable, `NA` means there is `No Alley` access to the property. By recoding these variables, we were able to fix most of the missing values in categorical variables.  

Variable Name   | Number of Missing Values
----------------|-------------------------
pool.qc         | 2917
misc.feature    | 2824         
alley           | 2732 
fence           | 2358
fireplace.qu    | 1422 
lot.frontage    | 490  
garage.yr.blt   | 159 
garage.qual     | 158
garage.cond     | 158   
garage.type     | 157
garage.finish   | 157   
bsmt.qual       | 79
bsmt.cond       | 79
bsmt.exposure   | 79
bsmtfin.type.1  | 79 
bsmtfin.type.2  | 79 

Table: Table 1: Number of Missing Values by Variable, Number Missing > 75

The solution to fill missing values for quantitative variables was just as simple. Most of the quantitative variables missing large numbers of values were `NA` because a given house feature was missing as well. For example, all missing values in the `garage.yr.blt` variable were because the house does not have a garage. The same reasoning for missing values applies to the square footage variables. For variables that were not missing a large number of variables we used mode (categorical) and median (quantitative) imputation to fill missing values.

Once the variables were cleaned and all missing values were filled, we performed exploratory data analysis of the data. We noticed that the distribution of sale price was heavily skewed to the right. For this reason...


[1]: http://www.stat.unc.edu/faculty/cji/fys/2012/Subprime%20mortgage%20crisis.pdf
[2]: cite the *Art of Data Science Book* here
[3]: *Journal of Statistics Education*, Volume 19, Number 3(2011), accessed April 11, 2017 at www.amstat.org/publications/jse/v19n3/decock.pdf

# Jack

# Paul

# Yesh

# Mike

